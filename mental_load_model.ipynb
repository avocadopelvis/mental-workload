{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mental-load-model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1cbYUxt1GX2jiTCdtLUfCV1tozRB0MpuA",
      "authorship_tag": "ABX9TyMxKfOx9jP1f94L/Uo8/I5E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avocadopelvis/mental-load/blob/main/mental_load_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "ypnKquskuawT"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use gpu if available \n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62DOKeozmzVw",
        "outputId": "b1eee257-e9c0-417a-9341-bbd9f7122509"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cpu device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/MENTAL-LOAD-DATASET/final.csv\")\n",
        "df = df.drop(df.columns[0], axis = 1)\n",
        "\n",
        "# split data into training & testing data\n",
        "train, test = train_test_split(df, test_size=0.15, random_state = 42)"
      ],
      "metadata": {
        "id": "VZEL-mN0RXF3"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "iZFpapJjlqJJ",
        "outputId": "0e651e3b-2ac6-4fa8-afde-afa47aabcbc6"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "1005  0.164014  0.166735  0.176727  0.196116  0.213293  0.219343  0.220973   \n",
              "1078  0.002929  0.022080  0.076195  0.160300  0.230544  0.240186  0.187798   \n",
              "67   -0.003629 -0.003397 -0.007976 -0.012933 -0.013669 -0.010251 -0.006219   \n",
              "867   0.048392  0.129867  0.240684  0.344691  0.380315  0.309278  0.155733   \n",
              "650   0.048999  0.049822  0.049900  0.050421  0.053110  0.058373  0.064244   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1380  0.026601  0.036793  0.046180  0.051023  0.053659  0.058344  0.065527   \n",
              "1493  0.185808  0.179980  0.170797  0.159328  0.147434  0.135170  0.120580   \n",
              "23    0.013307  0.015745  0.019292  0.022004  0.022628  0.021838  0.021186   \n",
              "1623 -0.111440 -0.111611 -0.110390 -0.108150 -0.105613 -0.102736 -0.099448   \n",
              "198  -0.024913 -0.052521 -0.078412 -0.096605 -0.106083 -0.109254 -0.109087   \n",
              "\n",
              "             7         8         9  ...      3831      3832      3833  \\\n",
              "1005  0.227681  0.236188  0.237621  ...  0.639941  0.849819  0.970012   \n",
              "1078  0.116244  0.067001  0.044995  ...  0.224582  0.206815  0.172710   \n",
              "67   -0.004303 -0.003996 -0.002730  ... -0.208054 -0.198667 -0.189793   \n",
              "867  -0.010854 -0.128992 -0.184842  ...  0.404173  0.373316  0.243216   \n",
              "650   0.068609  0.071240  0.072882  ... -0.035319 -0.034646 -0.029381   \n",
              "...        ...       ...       ...  ...       ...       ...       ...   \n",
              "1380  0.072273  0.076169  0.078490  ...  0.677449  0.286892  0.022926   \n",
              "1493  0.103737  0.087794  0.074350  ...  0.097044  0.086480  0.076435   \n",
              "23    0.021561  0.022855  0.024732  ...  0.002636  0.001347  0.001552   \n",
              "1623 -0.096677 -0.094984 -0.093612  ... -0.552531 -0.449544 -0.356508   \n",
              "198  -0.107343 -0.104942 -0.102688  ...  0.250991  0.255911  0.257518   \n",
              "\n",
              "          3834      3835      3836      3837      3838      3839  label  \n",
              "1005  0.898661  0.604743  0.176153 -0.223539 -0.453234 -0.465044      0  \n",
              "1078  0.138659  0.113362  0.088653  0.052213  0.002051 -0.053440      1  \n",
              "67   -0.180948 -0.172425 -0.165161 -0.159735 -0.155701 -0.151847      2  \n",
              "867   0.077017 -0.056813 -0.132946 -0.175498 -0.215404 -0.247424      2  \n",
              "650  -0.024503 -0.024758 -0.029238 -0.032256 -0.028894 -0.018963      2  \n",
              "...        ...       ...       ...       ...       ...       ...    ...  \n",
              "1380 -0.046464 -0.010843 -0.004386 -0.074311 -0.158254 -0.173879      1  \n",
              "1493  0.065483  0.052853  0.039080  0.024595  0.009500 -0.004568      1  \n",
              "23    0.002596  0.004134  0.005532  0.006023  0.005929  0.006296      1  \n",
              "1623 -0.284998 -0.233169 -0.193128 -0.153170 -0.100056 -0.026426      1  \n",
              "198   0.256429  0.255164  0.253675  0.249665  0.242915  0.236408      1  \n",
              "\n",
              "[315 rows x 3841 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1d21bfbe-0a9f-44b0-8c91-4d4d4680c69c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>3831</th>\n",
              "      <th>3832</th>\n",
              "      <th>3833</th>\n",
              "      <th>3834</th>\n",
              "      <th>3835</th>\n",
              "      <th>3836</th>\n",
              "      <th>3837</th>\n",
              "      <th>3838</th>\n",
              "      <th>3839</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1005</th>\n",
              "      <td>0.164014</td>\n",
              "      <td>0.166735</td>\n",
              "      <td>0.176727</td>\n",
              "      <td>0.196116</td>\n",
              "      <td>0.213293</td>\n",
              "      <td>0.219343</td>\n",
              "      <td>0.220973</td>\n",
              "      <td>0.227681</td>\n",
              "      <td>0.236188</td>\n",
              "      <td>0.237621</td>\n",
              "      <td>...</td>\n",
              "      <td>0.639941</td>\n",
              "      <td>0.849819</td>\n",
              "      <td>0.970012</td>\n",
              "      <td>0.898661</td>\n",
              "      <td>0.604743</td>\n",
              "      <td>0.176153</td>\n",
              "      <td>-0.223539</td>\n",
              "      <td>-0.453234</td>\n",
              "      <td>-0.465044</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1078</th>\n",
              "      <td>0.002929</td>\n",
              "      <td>0.022080</td>\n",
              "      <td>0.076195</td>\n",
              "      <td>0.160300</td>\n",
              "      <td>0.230544</td>\n",
              "      <td>0.240186</td>\n",
              "      <td>0.187798</td>\n",
              "      <td>0.116244</td>\n",
              "      <td>0.067001</td>\n",
              "      <td>0.044995</td>\n",
              "      <td>...</td>\n",
              "      <td>0.224582</td>\n",
              "      <td>0.206815</td>\n",
              "      <td>0.172710</td>\n",
              "      <td>0.138659</td>\n",
              "      <td>0.113362</td>\n",
              "      <td>0.088653</td>\n",
              "      <td>0.052213</td>\n",
              "      <td>0.002051</td>\n",
              "      <td>-0.053440</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>-0.003629</td>\n",
              "      <td>-0.003397</td>\n",
              "      <td>-0.007976</td>\n",
              "      <td>-0.012933</td>\n",
              "      <td>-0.013669</td>\n",
              "      <td>-0.010251</td>\n",
              "      <td>-0.006219</td>\n",
              "      <td>-0.004303</td>\n",
              "      <td>-0.003996</td>\n",
              "      <td>-0.002730</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.208054</td>\n",
              "      <td>-0.198667</td>\n",
              "      <td>-0.189793</td>\n",
              "      <td>-0.180948</td>\n",
              "      <td>-0.172425</td>\n",
              "      <td>-0.165161</td>\n",
              "      <td>-0.159735</td>\n",
              "      <td>-0.155701</td>\n",
              "      <td>-0.151847</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>867</th>\n",
              "      <td>0.048392</td>\n",
              "      <td>0.129867</td>\n",
              "      <td>0.240684</td>\n",
              "      <td>0.344691</td>\n",
              "      <td>0.380315</td>\n",
              "      <td>0.309278</td>\n",
              "      <td>0.155733</td>\n",
              "      <td>-0.010854</td>\n",
              "      <td>-0.128992</td>\n",
              "      <td>-0.184842</td>\n",
              "      <td>...</td>\n",
              "      <td>0.404173</td>\n",
              "      <td>0.373316</td>\n",
              "      <td>0.243216</td>\n",
              "      <td>0.077017</td>\n",
              "      <td>-0.056813</td>\n",
              "      <td>-0.132946</td>\n",
              "      <td>-0.175498</td>\n",
              "      <td>-0.215404</td>\n",
              "      <td>-0.247424</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>650</th>\n",
              "      <td>0.048999</td>\n",
              "      <td>0.049822</td>\n",
              "      <td>0.049900</td>\n",
              "      <td>0.050421</td>\n",
              "      <td>0.053110</td>\n",
              "      <td>0.058373</td>\n",
              "      <td>0.064244</td>\n",
              "      <td>0.068609</td>\n",
              "      <td>0.071240</td>\n",
              "      <td>0.072882</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.035319</td>\n",
              "      <td>-0.034646</td>\n",
              "      <td>-0.029381</td>\n",
              "      <td>-0.024503</td>\n",
              "      <td>-0.024758</td>\n",
              "      <td>-0.029238</td>\n",
              "      <td>-0.032256</td>\n",
              "      <td>-0.028894</td>\n",
              "      <td>-0.018963</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1380</th>\n",
              "      <td>0.026601</td>\n",
              "      <td>0.036793</td>\n",
              "      <td>0.046180</td>\n",
              "      <td>0.051023</td>\n",
              "      <td>0.053659</td>\n",
              "      <td>0.058344</td>\n",
              "      <td>0.065527</td>\n",
              "      <td>0.072273</td>\n",
              "      <td>0.076169</td>\n",
              "      <td>0.078490</td>\n",
              "      <td>...</td>\n",
              "      <td>0.677449</td>\n",
              "      <td>0.286892</td>\n",
              "      <td>0.022926</td>\n",
              "      <td>-0.046464</td>\n",
              "      <td>-0.010843</td>\n",
              "      <td>-0.004386</td>\n",
              "      <td>-0.074311</td>\n",
              "      <td>-0.158254</td>\n",
              "      <td>-0.173879</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1493</th>\n",
              "      <td>0.185808</td>\n",
              "      <td>0.179980</td>\n",
              "      <td>0.170797</td>\n",
              "      <td>0.159328</td>\n",
              "      <td>0.147434</td>\n",
              "      <td>0.135170</td>\n",
              "      <td>0.120580</td>\n",
              "      <td>0.103737</td>\n",
              "      <td>0.087794</td>\n",
              "      <td>0.074350</td>\n",
              "      <td>...</td>\n",
              "      <td>0.097044</td>\n",
              "      <td>0.086480</td>\n",
              "      <td>0.076435</td>\n",
              "      <td>0.065483</td>\n",
              "      <td>0.052853</td>\n",
              "      <td>0.039080</td>\n",
              "      <td>0.024595</td>\n",
              "      <td>0.009500</td>\n",
              "      <td>-0.004568</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0.013307</td>\n",
              "      <td>0.015745</td>\n",
              "      <td>0.019292</td>\n",
              "      <td>0.022004</td>\n",
              "      <td>0.022628</td>\n",
              "      <td>0.021838</td>\n",
              "      <td>0.021186</td>\n",
              "      <td>0.021561</td>\n",
              "      <td>0.022855</td>\n",
              "      <td>0.024732</td>\n",
              "      <td>...</td>\n",
              "      <td>0.002636</td>\n",
              "      <td>0.001347</td>\n",
              "      <td>0.001552</td>\n",
              "      <td>0.002596</td>\n",
              "      <td>0.004134</td>\n",
              "      <td>0.005532</td>\n",
              "      <td>0.006023</td>\n",
              "      <td>0.005929</td>\n",
              "      <td>0.006296</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1623</th>\n",
              "      <td>-0.111440</td>\n",
              "      <td>-0.111611</td>\n",
              "      <td>-0.110390</td>\n",
              "      <td>-0.108150</td>\n",
              "      <td>-0.105613</td>\n",
              "      <td>-0.102736</td>\n",
              "      <td>-0.099448</td>\n",
              "      <td>-0.096677</td>\n",
              "      <td>-0.094984</td>\n",
              "      <td>-0.093612</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.552531</td>\n",
              "      <td>-0.449544</td>\n",
              "      <td>-0.356508</td>\n",
              "      <td>-0.284998</td>\n",
              "      <td>-0.233169</td>\n",
              "      <td>-0.193128</td>\n",
              "      <td>-0.153170</td>\n",
              "      <td>-0.100056</td>\n",
              "      <td>-0.026426</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>-0.024913</td>\n",
              "      <td>-0.052521</td>\n",
              "      <td>-0.078412</td>\n",
              "      <td>-0.096605</td>\n",
              "      <td>-0.106083</td>\n",
              "      <td>-0.109254</td>\n",
              "      <td>-0.109087</td>\n",
              "      <td>-0.107343</td>\n",
              "      <td>-0.104942</td>\n",
              "      <td>-0.102688</td>\n",
              "      <td>...</td>\n",
              "      <td>0.250991</td>\n",
              "      <td>0.255911</td>\n",
              "      <td>0.257518</td>\n",
              "      <td>0.256429</td>\n",
              "      <td>0.255164</td>\n",
              "      <td>0.253675</td>\n",
              "      <td>0.249665</td>\n",
              "      <td>0.242915</td>\n",
              "      <td>0.236408</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>315 rows Ã— 3841 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1d21bfbe-0a9f-44b0-8c91-4d4d4680c69c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1d21bfbe-0a9f-44b0-8c91-4d4d4680c69c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1d21bfbe-0a9f-44b0-8c91-4d4d4680c69c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SignalDataset(Dataset):\n",
        "    def __init__(self, df):\n",
        "      # get x and convert to tensor\n",
        "      self.x = torch.tensor(df.iloc[:, 0:3840].values)\n",
        "      # get y and convert to tensor\n",
        "      self.y = torch.tensor(df[\"label\"].values)\n",
        "      # get number of samples\n",
        "      self.n_samples = df.shape[0]\n",
        "\n",
        "    def __len__(self):\n",
        "      return self.n_samples\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      return self.x[index], self.y[index]"
      ],
      "metadata": {
        "id": "OHEkU17GwBfg"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = SignalDataset(train)\n",
        "test_dataset = SignalDataset(test)"
      ],
      "metadata": {
        "id": "f0V1egMmZSNs"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=10, shuffle=True) #,num_workers = 2\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
      ],
      "metadata": {
        "id": "anGZpUcGkO8s"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparameters\n",
        "input_size = 3840\n",
        "hidden_size = 2500 \n",
        "num_classes = 3\n",
        "num_epochs = 20\n",
        "batch_size = 64\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "NQVhOJbHmdYN"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# FULLY CONNECTED NEURAL NETWORK\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "  def __init__(self, input_size, hidden_size, num_classes):\n",
        "    super(NeuralNetwork, self).__init__()\n",
        "    self.l1 = nn.Linear(input_size, hidden_size)\n",
        "    self.relu = nn.ReLU()\n",
        "    self.l2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out = self.l1(x)\n",
        "    out = self.relu(out)\n",
        "    out = self.l2(out)\n",
        "    return out\n",
        "\n",
        "model = NeuralNetwork(input_size, hidden_size, num_classes)\n",
        "print(model)"
      ],
      "metadata": {
        "id": "SRhXLS_7IiKa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43fb5ab3-191f-40e4-dc9c-f0fe3017be08"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (l1): Linear(in_features=3840, out_features=2500, bias=True)\n",
            "  (relu): ReLU()\n",
            "  (l2): Linear(in_features=2500, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LOSS & OPTIMIZER\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr= learning_rate, momentum=0.9)"
      ],
      "metadata": {
        "id": "YZVawr1_oZ9o"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TRAINING LOOP\n",
        "n_total_steps = len(train_dataloader)\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "  for i, data in enumerate(train_dataloader, 0):\n",
        "    # get the inputs and labels\n",
        "    inputs, labels = data\n",
        "\n",
        "    # forward\n",
        "    outputs = model(inputs.float())\n",
        "    loss = criterion(outputs, labels)\n",
        "\n",
        "    # backward\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (i+1)%100 == 0:\n",
        "      print(f'epoch {epoch+1} / {num_epochs}, step {i+1} / {n_total_steps}, loss = {loss.item():.4f}')\n",
        "\n",
        "print(\"Finished Training\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2ukRUHoKRRZ",
        "outputId": "8630ed1e-a867-4325-86a8-31fd5d3a076a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch 1 / 20, step 100 / 179, loss = 1.3742\n",
            "epoch 2 / 20, step 100 / 179, loss = 0.6643\n",
            "epoch 3 / 20, step 100 / 179, loss = 0.6298\n",
            "epoch 4 / 20, step 100 / 179, loss = 0.3719\n",
            "epoch 5 / 20, step 100 / 179, loss = 0.1794\n",
            "epoch 6 / 20, step 100 / 179, loss = 0.0374\n",
            "epoch 7 / 20, step 100 / 179, loss = 0.0096\n",
            "epoch 8 / 20, step 100 / 179, loss = 0.0427\n",
            "epoch 9 / 20, step 100 / 179, loss = 0.0035\n",
            "epoch 10 / 20, step 100 / 179, loss = 0.0020\n",
            "epoch 11 / 20, step 100 / 179, loss = 0.2903\n",
            "epoch 12 / 20, step 100 / 179, loss = 0.0073\n",
            "epoch 13 / 20, step 100 / 179, loss = 0.4878\n",
            "epoch 14 / 20, step 100 / 179, loss = 0.0271\n",
            "epoch 15 / 20, step 100 / 179, loss = 0.0194\n",
            "epoch 16 / 20, step 100 / 179, loss = 0.0003\n",
            "epoch 17 / 20, step 100 / 179, loss = 0.0007\n",
            "epoch 18 / 20, step 100 / 179, loss = 0.0016\n",
            "epoch 19 / 20, step 100 / 179, loss = 0.0001\n",
            "epoch 20 / 20, step 100 / 179, loss = 0.0000\n",
            "Finished Training\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TESTING\n",
        "with torch.no_grad():\n",
        "  n_correct = 0\n",
        "  n_samples = 0\n",
        "  for inputs, labels in test_dataloader:\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = model(inputs.float())\n",
        "\n",
        "    # value, index (We don't need value)\n",
        "    _, predictions = torch.max(outputs, 1)\n",
        "    n_samples += labels.shape[0]\n",
        "    n_correct += (predictions == labels).sum().item()\n",
        "\n",
        "  acc = 100.0 * n_correct / n_samples\n",
        "  print(f'accuracy = {acc}')"
      ],
      "metadata": {
        "id": "ITY958BaSv5R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b1d44d2-7408-43e0-8ae6-fbca86a0b6b6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy = 41.26984126984127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MHm9uXjtjbba"
      },
      "execution_count": 56,
      "outputs": []
    }
  ]
}